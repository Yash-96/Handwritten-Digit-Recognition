# -*- coding: utf-8 -*-
"""Untitled1.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1cqAnjOoY4TSBkBWX2l1GLKIPu7yr13Ar
"""

from google.colab import drive
drive.mount('/content/drive')

!pip install mlxtend

"""# *Libraries*

---
"""

import gzip, pickle
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
# %matplotlib inline
from scipy import stats
from sklearn.metrics import confusion_matrix, classification_report
from keras.utils import np_utils
from keras.models import Sequential
from keras.layers import Dense, Activation, Dropout, Flatten
from keras.callbacks import EarlyStopping, TensorBoard
from sklearn.svm import SVC
from sklearn.ensemble import RandomForestClassifier
from sklearn.neural_network import MLPClassifier
from sklearn.linear_model import LogisticRegression
from sklearn.ensemble import BaggingClassifier
from sklearn.model_selection import cross_val_score
from mlxtend.classifier import StackingClassifier
from sklearn.ensemble import AdaBoostClassifier

"""# MNIST Data

---
"""

with gzip.open('/content/drive/My Drive/mnist.pkl.gz','rb') as ff :
    u = pickle._Unpickler( ff )
    u.encoding = 'latin1'
    train, val, test = u.load()

print( train[0].shape, train[1].shape )
print( val[0].shape, val[1].shape )
print( test[0].shape, test[1].shape )

num_classes = 10
num_features = 784
eta = 0.02
final=[]
final_image=[]
input_size = 784
drop_out = 0.1
first_dense_layer_nodes  = 1568
second_dense_layer_nodes = 10
validation_data_split = 0.0
num_epochs = 50
model_batch_size = 1024
tb_batch_size = 32
early_patience = 100

"""## Logistic Reression I

---
"""

def softmax(Z, epsilon=1e-9):
    e = np.exp(Z - np.max(Z))
    # very tiny epsilon to the result of softmax function output, to avoid applying logarithm to zeros
    if e.ndim == 1:
        return e / np.sum(e, axis=0) + epsilon
    else:  
        return e / np.array([np.sum(e, axis=1)]).T + epsilon

def infer(W, X):
    #use of np.hstack to add additional column of ones to X;

    X_ones = np.hstack((X, np.ones(((X.shape[0]), 1))))
    XW = np.dot(X_ones, W)
    smax = softmax(XW)
    return smax

def one_hot_encode(labels_list, max_number):
   
    b= np_utils.to_categorical(np.array(labels_list),max_number)
    return b

def loss(W, X, Y):

    m = X.shape[0]
    T = infer(W, X)    
    return (-1 / m) * np.sum(np.log(T) * Y) + eta / 2 * np.sum(W * W)

y_onehot = one_hot_encode(train[1], num_classes)
                          
def get_grad(W, X, Y):
  
    X_alt = np.hstack((X, np.ones(((X.shape[0]), 1))))
    m = X.shape[0]
    T = infer(W, X)   
    return (-1 / m) * np.dot(X_alt.T, (Y - T)) + eta * W

def training(X_train, y_train, batch_size=100, num_epoch=1, n_classes=num_classes, lr=0.001, plot_loss=True):
    
    #Perform gradient descent and return trained weights;
        
    losses = []
    n_features = num_features
    w = np.random.randn(n_features+1, n_classes)/n_features
    for epoch in range(num_epoch):
#         grad = get_grad(w, X_train, one_hot_encode(y_train, n_classes))
#         # print(grad)
#         w = w - step * grad
#         # print(w)
#         losses.append(loss(w, X_train, one_hot_encode(y_train, n_classes)))
        
        for iter_num, (x_batch, y_batch) in enumerate(zip(np.split(X_train, batch_size), np.split(y_train, batch_size))):
            grad = get_grad(w, x_batch, one_hot_encode(y_batch, n_classes))
            gradient_step = lr * grad
            # print(gradient_step)
            w -= gradient_step
            # print(w)
            losses.append(loss(w, x_batch, one_hot_encode(y_batch, n_classes)))
            
    if plot_loss:
        plt.plot(losses)
        plt.title("Loss")
        plt.xlabel("epoch*batches")
        plt.show()
        
    return w

def make_prediction(X, W):

    probability_matrix = infer(W, X)
    return np.array([np.argmax(t) for t in probability_matrix])

import time
start_time = time.time()
W = training(train[0], train[1], num_epoch=100)
print("--- %s seconds ---" % (time.time() - start_time))

print("Validation Logistic Regression I")
right=0
wrong=0
y_pred = make_prediction(val[0], W)
for i,j in zip(val[1],y_pred):
    if i==j:
        right = right + 1
    else:
        wrong = wrong + 1
print("Accuracy: " + str(right/(right+wrong)*100)) 
print(classification_report(val[1], y_pred))
print(confusion_matrix(val[1], y_pred))
print("Testing Logistic Regression I")

right=0
wrong=0
y_pred = make_prediction(test[0], W)
for i,j in zip(test[1],y_pred):
    if i==j:
        right = right + 1
    else:
        wrong = wrong + 1
print("Accuracy: " + str(right/(right+wrong)*100)) 
print(classification_report(test[1], y_pred))
print(confusion_matrix(test[1], y_pred))
final.append(y_pred)

"""## Neural Network I

---
"""

def get_model():

    model = Sequential()
    
    model.add(Dense(first_dense_layer_nodes, input_dim=input_size))
    model.add(Activation('sigmoid'))
    model.add(Dropout(drop_out))
    
    model.add(Dense(first_dense_layer_nodes))
    model.add(Activation('sigmoid'))
    model.add(Dropout(drop_out))

    model.add(Dense(second_dense_layer_nodes))
    model.add(Activation('softmax'))
   
    
    
    model.compile(optimizer='adadelta',
                  loss='categorical_crossentropy',
                  metrics=['accuracy'])
    
    return model

model = get_model()
start_time = time.time()
tensorboard_cb   = TensorBoard(log_dir='logs', batch_size= tb_batch_size, write_graph= True)
earlystopping_cb = EarlyStopping(monitor='val_loss', verbose=0, patience=early_patience, mode='min')
history = model.fit((train[0])
                    , y_onehot
                    , validation_split=validation_data_split
                    , epochs=num_epochs
                    , batch_size=model_batch_size
                    , callbacks = [tensorboard_cb,earlystopping_cb]
                   )
print("--- %s seconds ---" % (time.time() - start_time))

print("Validation NN I")

right=0
wrong=0
predictedTestLabel=[]
for i,j in zip((val[0]),val[1]):
    y = model.predict(np.array(i).reshape(-1,784))
    
    predictedTestLabel.append(y.argmax())
    
    if j == y.argmax():
        right = right + 1
    else:
        wrong = wrong + 1

#print("Errors: " + str(wrong), " Correct :" + str(right))
print("Accuracy: " + str(right/(right+wrong)*100))
print(classification_report(val[1], predictedTestLabel))
print(confusion_matrix(val[1], predictedTestLabel))

print("Testing NN I")

right=0
wrong=0
predictedTestLabel=[]
for i,j in zip((test[0]),test[1]):
    y = model.predict(np.array(i).reshape(-1,784))
    
    predictedTestLabel.append(y.argmax())
    
    if j == y.argmax():
        right = right + 1
    else:
        wrong = wrong + 1

#print("Errors: " + str(wrong), " Correct :" + str(right))
print("Accuracy: " + str(right/(right+wrong)*100))
print(classification_report(test[1], predictedTestLabel))
print(confusion_matrix(test[1], predictedTestLabel))
final.append(predictedTestLabel)

def accuracy(clf,train,test):
  right=0
  wrong=0
  y_pred = clf.predict(train)
  for i,j in zip(test,y_pred):
      if i==j:
          right = right + 1
      else:
          wrong = wrong + 1
  print("Accuracy: " + str(right/(right+wrong)*100)) 
  print(classification_report(test, y_pred))
  print(confusion_matrix(test, y_pred))
  final.append(y_pred)

"""## Logistic Regression II & III

---
"""

clf_LR1 = LogisticRegression(random_state=0, solver='lbfgs',multi_class='ovr')
clf_LR2 = LogisticRegression(random_state=0, solver='lbfgs',multi_class='multinomial')
start_time = time.time()
clf_LR1.fit(train[0], train[1])
print("--- %s seconds ---" % (time.time() - start_time))
start_time = time.time()
clf_LR2.fit(train[0], train[1])
print("--- %s seconds ---" % (time.time() - start_time))

accuracy(clf_LR1,test[0],test[1])
accuracy(clf_LR2,test[0],test[1])

"""## Neural Network II & III

---
"""

clf_NN1 = MLPClassifier(solver='adam',alpha=0.01,learning_rate='adaptive',hidden_layer_sizes=(256, 2),random_state=1,max_iter=50)  
clf_NN2 = MLPClassifier(solver='sgd',alpha=0.01,learning_rate='adaptive',hidden_layer_sizes=(256, 2),random_state=1,max_iter=50)    
start_time = time.time()
clf_NN1.fit(train[0], train[1])
print("--- %s seconds ---" % (time.time() - start_time))
start_time = time.time()
clf_NN2.fit(train[0], train[1])
print("--- %s seconds ---" % (time.time() - start_time))

accuracy(clf_NN1,test[0],test[1])
accuracy(clf_NN2,test[0],test[1])

"""## Convolutional NN"""

class AccuracyHistory(keras.callbacks.Callback):
    def on_train_begin(self, logs={}):
        self.acc = []

    def on_epoch_end(self, batch, logs={}):
        self.acc.append(logs.get('acc'))

history = AccuracyHistory()

from keras.layers.convolutional import Conv2D,MaxPooling2D
CNN_model = Sequential()
CNN_model.add(Conv2D(32, kernel_size=(5, 5), strides=(1, 1),
                 activation='sigmoid',
                 input_shape=(28,28,1)))
CNN_model.add(MaxPooling2D(pool_size=(2, 2), strides=(2, 2)))
CNN_model.add(Conv2D(64, (5, 5), activation='sigmoid'))
CNN_model.add(MaxPooling2D(pool_size=(2, 2)))
CNN_model.add(Flatten())
CNN_model.add(Dense(1000, activation='relu'))
CNN_model.add(Dense(10, activation='softmax'))

import keras
import keras.utils
(X_train, y_train)=(train[0],one_hot_encode(train[1], num_classes))
(X_test, y_test)=(test[0],one_hot_encode(test[1], num_classes))
X_train = X_train.reshape(X_train.shape[0], 28, 28, 1)
X_test = X_test.reshape(X_test.shape[0], 28, 28, 1)
CNN_model.compile(loss=keras.losses.categorical_crossentropy,
              optimizer=keras.optimizers.Adadelta(),
              metrics=['accuracy'])

CNN_model.fit(X_train, y_train,
          batch_size=64,
          epochs=32,
          verbose=1,
          validation_data=(X_test, y_test),
          callbacks=[history])

score = CNN_model.evaluate(X_test, y_test, verbose=0)
y_pred=CNN_model.predict(X_test)
y_pred=np.array([np.argmax(t) for t in y_pred])
right=0
wrong=0
for i,j in zip(test[1],y_pred):
    if i==j:
        right = right + 1
    else:
        wrong = wrong + 1
print("Accuracy: " + str(right/(right+wrong)*100)) 
print(classification_report(test[1], y_pred))
print(confusion_matrix(test[1], y_pred))
print('Test accuracy:', score[1])

"""## Random Forest 

---
"""

clf_RBF1 = RandomForestClassifier(n_estimators=10)
clf_RBF2 = RandomForestClassifier(n_estimators=100)
clf_RBF3 = RandomForestClassifier(n_estimators=200)
start_time = time.time()
clf_RBF1.fit(train[0], train[1])
print("--- %s seconds ---" % (time.time() - start_time))
start_time = time.time()
clf_RBF2.fit(train[0], train[1]) 
print("--- %s seconds ---" % (time.time() - start_time))
start_time = time.time()
clf_RBF3.fit(train[0], train[1]) 
print("--- %s seconds ---" % (time.time() - start_time))

accuracy(clf_RBF1,test[0],test[1])
accuracy(clf_RBF2,test[0],test[1])
accuracy(clf_RBF3,test[0],test[1])

m = stats.mode(np.array(final))
print(np.array(final).shape)
right=0
wrong=0
for i,j in zip(test[1], m[0][0]):
    
    if i == j:
        right = right + 1
    else:
        wrong = wrong + 1

print("Errors: " + str(wrong), " Correct :" + str(right))
print("Accuracy: " + str(right/(right+wrong)*100))
print(classification_report(test[1], m[0][0]))
print(confusion_matrix(test[1], m[0][0]))

"""## Support Vector Machine

---
"""

clf1 = SVC(kernel='linear')
clf2 = SVC(kernel='rbf', gamma=1)
clf3 = SVC(kernel='rbf')
start_time = time.time()
clf1.fit(train[0], train[1])
print("--- %s seconds ---" % (time.time() - start_time))
start_time = time.time()
clf3.fit(train[0], train[1]) 
print("--- %s seconds ---" % (time.time() - start_time))

start_time = time.time()
clf2.fit(train[0], train[1]) 
print("--- %s seconds ---" % (time.time() - start_time))
accuracy(clf2,test[0],test[1])

accuracy(clf1,test[0],test[1])
accuracy(clf3,test[0],test[1])

"""### Majority Voting"""

m = stats.mode(np.array(final))
print(np.array(final).shape)
right=0
wrong=0
for i,j in zip(test[1], m[0][0]):
    
    if i == j:
        right = right + 1
    else:
        wrong = wrong + 1

print("Errors: " + str(wrong), " Correct :" + str(right))
print("Accuracy: " + str(right/(right+wrong)*100))
print(classification_report(test[1], m[0][0]))
print(confusion_matrix(test[1], m[0][0]))

"""## Bagging

---
"""

bagging1 = BaggingClassifier(base_estimator=clf_LR2, n_estimators=5, max_samples=0.8, max_features=0.8)
bagging2 = BaggingClassifier(base_estimator=clf_NN1, n_estimators=5, max_samples=0.8, max_features=0.8)
bagging3 = BaggingClassifier(base_estimator=clf_RBF1, n_estimators=5, max_samples=0.8, max_features=0.8)
bagging4 = BaggingClassifier(base_estimator=clf1, n_estimators=5, max_samples=0.8, max_features=0.8)
start_time = time.time()
bagging1.fit(train[0], train[1]) 
print("--- %s seconds ---" % (time.time() - start_time))
start_time = time.time()
bagging2.fit(train[0], train[1]) 
print("--- %s seconds ---" % (time.time() - start_time))
start_time = time.time()
bagging3.fit(train[0], train[1])
print("--- %s seconds ---" % (time.time() - start_time))
start_time = time.time()
bagging4.fit(train[0], train[1]) 
print("--- %s seconds ---" % (time.time() - start_time))

accuracy(bagging1,test[0],test[1])
accuracy(bagging2,test[0],test[1])
accuracy(bagging3,test[0],test[1])
accuracy(bagging4,test[0],test[1])

"""## Boosting

---
"""

boosting4 = AdaBoostClassifier(base_estimator=clf1, n_estimators=5, algorithm='SAMME')
start_time = time.time()
boosting4.fit(train[0], train[1]) 
print("--- %s seconds ---" % (time.time() - start_time))
accuracy(boosting4,test[0],test[1])

boosting1 = AdaBoostClassifier(base_estimator=clf_LR2, n_estimators=5)
boosting3 = AdaBoostClassifier(base_estimator=clf_RBF1, n_estimators=5)
start_time = time.time()
boosting1.fit(train[0], train[1]) 
print("--- %s seconds ---" % (time.time() - start_time))
start_time = time.time()
boosting3.fit(train[0], train[1])
print("--- %s seconds ---" % (time.time() - start_time))

accuracy(boosting1,test[0],test[1])
accuracy(boosting3,test[0],test[1])

np.array(final).shape
m = stats.mode(np.array(final))
print(m[0][0])
right=0
wrong=0
for i,j in zip(test[1], m[0][0]):
    
    if i == j:
        right = right + 1
    else:
        wrong = wrong + 1

print("Errors: " + str(wrong), " Correct :" + str(right))
print("Accuracy: " + str(right/(right+wrong)*100))
print(classification_report(test[1], m[0][0]))
print(confusion_matrix(test[1], m[0][0]))

"""## Stacking

---
"""

clf_SVM = SVC(kernel='linear', probability=True)
sclf1 = StackingClassifier(classifiers=[clf_SVM, clf_NN1, clf_RBF1], meta_classifier=clf_LR2)
sclf2 = StackingClassifier(classifiers=[clf_SVM, clf_NN1, clf_RBF1], use_probas=True, average_probas=False, meta_classifier=clf_LR2)
sclf3 = StackingClassifier(classifiers=[clf_SVM, clf_NN1, clf_RBF1], use_probas=True, average_probas=True, meta_classifier=clf_LR2)
start_time = time.time()
sclf1.fit(train[0], train[1]) 
print("--- %s seconds ---" % (time.time() - start_time))
start_time = time.time()
sclf2.fit(train[0], train[1]) 
print("--- %s seconds ---" % (time.time() - start_time))
start_time = time.time()
sclf3.fit(train[0], train[1])
print("--- %s seconds ---" % (time.time() - start_time))

accuracy(sclf1,test[0],test[1])
accuracy(sclf2,test[0],test[1])
accuracy(sclf3,test[0],test[1])

"""### Final Majority Voting"""

m = stats.mode(np.array(final))
print(np.array(final).shape)
right=0
wrong=0
for i,j in zip(test[1], m[0][0]):
    
    if i == j:
        right = right + 1
    else:
        wrong = wrong + 1

print("Errors: " + str(wrong), " Correct :" + str(right))
print("Accuracy: " + str(right/(right+wrong)*100))
print(classification_report(test[1], m[0][0]))
print(confusion_matrix(test[1], m[0][0]))

"""#**USPS DATA ** 

---
"""

usps_final=[]
def usps_accuracy(clf,train,test):
  right=0
  wrong=0
  y_pred = clf.predict(train)
  for i,j in zip(test,y_pred):
      if i==j:
          right = right + 1
      else:
          wrong = wrong + 1
  print("Accuracy: " + str(right/(right+wrong)*100)) 
  print(classification_report(test, y_pred))
  print(confusion_matrix(test, y_pred))
  usps_final.append(y_pred)

from PIL import Image
import glob
import cv2
image_list = []
target=[]
for i in range(0,10):
    for filename in glob.glob('/content/drive/My Drive/Numerals/'+str(i)+'/*.png'): 
        print(filename)
        im=cv2.imread (filename)
        im=cv2.cvtColor(im, cv2.COLOR_BGR2GRAY)
        im=1-(im/255)
        im=np.array(im)
        im=cv2.resize(im, (28, 28)).flatten() 
        image_list.append(im)
        target.append(i)
count=0 
for filename in glob.glob('/content/drive/My Drive/Test/*.png'): 
    im=cv2.imread (filename)
    im=cv2.cvtColor(im, cv2.COLOR_BGR2GRAY)
    im=1-(im/255)
    im=np.array(im)
    im=cv2.resize(im, (28, 28)).flatten() 
    image_list.append(im)
    target.append(9-(int(count/150)))
    count=count+1
image_list=np.array(image_list)
print(image_list.shape) 
print(np.array(target).shape)

image_list=image_list[0:19999][:]
target=target[0:19999]
print(image_list.shape) 
print(np.array(target).shape)

"""## Logistic Regression I"""

right=0
wrong=0
y_pred = make_prediction(image_list, W)
for i,j in zip(target,y_pred):
    if i==j:
        right = right + 1
    else:
        wrong = wrong + 1
print("Accuracy: " + str(right/(right+wrong)*100)) 
print(classification_report(target, y_pred))
print(confusion_matrix(target, y_pred))
usps_final.append(y_pred)

"""## Neural Network I"""

right=0
wrong=0
predictedTestLabel=[]
for i,j in zip(image_list,target):
    y = model.predict(np.array(i).reshape(-1,784))
    
    predictedTestLabel.append(y.argmax())
    
    if j == y.argmax():
        right = right + 1
    else:
        wrong = wrong + 1

#print("Errors: " + str(wrong), " Correct :" + str(right))
print("Accuracy: " + str(right/(right+wrong)*100))
print(classification_report(target, predictedTestLabel))
print(confusion_matrix(target, predictedTestLabel))
usps_final.append(predictedTestLabel)

"""## Logistic Regression II & III"""

usps_accuracy(clf_LR1,image_list,target)
usps_accuracy(clf_LR2,image_list,target)

"""## Neural Network II & III"""

usps_accuracy(clf_NN1,image_list,target)
usps_accuracy(clf_NN2,image_list,target)

"""## CNN"""

(X_test, y_test)=(np.array(image_list),one_hot_encode(target, num_classes))
X_test = X_test.reshape(X_test.shape[0], 28, 28, 1)
score = CNN_model.evaluate(X_test, y_test, verbose=0)
y_pred=CNN_model.predict(X_test)
y_pred=np.array([np.argmax(t) for t in y_pred])
right=0
wrong=0
for i,j in zip(target,y_pred):
    if i==j:
        right = right + 1
    else:
        wrong = wrong + 1
print("Accuracy: " + str(right/(right+wrong)*100)) 
print(classification_report(target, y_pred))
print(confusion_matrix(target, y_pred))
print('Test accuracy:', score[1])

"""## RBF"""

usps_accuracy(clf_RBF1,image_list,target)
usps_accuracy(clf_RBF2,image_list,target)
usps_accuracy(clf_RBF3,image_list,target)

"""## SVM"""

usps_accuracy(clf1,image_list,target)
usps_accuracy(clf3,image_list,target)

usps_accuracy(clf2,image_list,target)

"""### Majority Voting"""

m = stats.mode(np.array(usps_final))
print(np.array(usps_final).shape)
right=0
wrong=0
for i,j in zip(target, m[0][0]):
    
    if i == j:
        right = right + 1
    else:
        wrong = wrong + 1

print("Errors: " + str(wrong), " Correct :" + str(right))
print("Accuracy: " + str(right/(right+wrong)*100))
print(classification_report(target, m[0][0]))
print(confusion_matrix(target, m[0][0]))

"""## Boosting"""

usps_accuracy(boosting1,image_list,target)
usps_accuracy(boosting3,image_list,target)

usps_accuracy(boosting4,image_list,target)

m = stats.mode(np.array(usps_final))
print(np.array(usps_final).shape)
right=0
wrong=0
for i,j in zip(target, m[0][0]):
    
    if i == j:
        right = right + 1
    else:
        wrong = wrong + 1

print("Errors: " + str(wrong), " Correct :" + str(right))
print("Accuracy: " + str(right/(right+wrong)*100))
print(classification_report(target, m[0][0]))
print(confusion_matrix(target, m[0][0]))

"""## Bagging"""

usps_accuracy(bagging1,image_list,target)
usps_accuracy(bagging2,image_list,target)
usps_accuracy(bagging3,image_list,target)
usps_accuracy(bagging4,image_list,target)

m = stats.mode(np.array(usps_final))
print(np.array(usps_final).shape)
right=0
wrong=0
for i,j in zip(target, m[0][0]):
    
    if i == j:
        right = right + 1
    else:
        wrong = wrong + 1

print("Errors: " + str(wrong), " Correct :" + str(right))
print("Accuracy: " + str(right/(right+wrong)*100))
print(classification_report(target, m[0][0]))
print(confusion_matrix(target, m[0][0]))

"""## Stacking"""

usps_accuracy(sclf1,image_list,target)
usps_accuracy(sclf2,image_list,target)
usps_accuracy(sclf3,image_list,target)

"""### Final Majority Voting"""

m = stats.mode(np.array(usps_final))
print(np.array(usps_final).shape)
right=0
wrong=0
for i,j in zip(target, m[0][0]):
    
    if i == j:
        right = right + 1
    else:
        wrong = wrong + 1

print("Errors: " + str(wrong), " Correct :" + str(right))
print("Accuracy: " + str(right/(right+wrong)*100))
print(classification_report(target, m[0][0]))
print(confusion_matrix(target, m[0][0]))

